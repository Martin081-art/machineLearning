import pandas as pd

# Load the CSV file
df = pd.read_csv("data.csv")

# Show first few rows
df.head()
/////////////////////////
# Show first 10 rows for each column
for col in df.columns:
    print(f"Column: {col}")
    print(df[col].head(10))
    print("-" * 50)
////////////
binary_cols = ['Gender', 'Displaced', 'Scholarship holder', 'Tuition fees up to date', 'Educational special needs', 'International', 'Daytime/evening attendance\t']

for col in binary_cols:
    print(f"Column: {col}")
    print("Missing values:", df[col].isnull().sum())
    print("Value counts:\n", df[col].value_counts())
    print("-"*50)
//////////////////////////////////
import seaborn as sns
import matplotlib.pyplot as plt

# Compute correlation matrix
corr_matrix = df.corr(numeric_only=True)

# Display correlation heatmap
plt.figure(figsize=(10,8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Matrix of Numeric Features")
plt.show()
//////////////////////////////////////////////////////////
import matplotlib.pyplot as plt
import seaborn as sns

# Set a clean, modern style for all charts
sns.set(style="whitegrid")

# 1️⃣ AGE AT ENROLLMENT vs TARGET
plt.figure(figsize=(8, 5))
sns.boxplot(x='Target', y='Age at enrollment', data=df)
plt.title('Age at Enrollment vs Target (Dropout, Enrolled, Graduate)', fontsize=12)
plt.xlabel('Student Status')
plt.ylabel('Age at Enrollment')
plt.show()

# 2️⃣ GENDER vs TARGET
plt.figure(figsize=(6, 4))
sns.countplot(x='Gender', hue='Target', data=df)
plt.title('Gender vs Target', fontsize=12)
plt.xlabel('Gender (0 = Female, 1 = Male)')
plt.ylabel('Count')
plt.show()

# 3️⃣ MARITAL STATUS vs TARGET
plt.figure(figsize=(8, 5))
sns.countplot(x='Marital status', hue='Target', data=df)
plt.title('Marital Status vs Target', fontsize=12)
plt.xlabel('Marital Status (1 = Single, 2 = Married, etc.)')
plt.ylabel('Count')
plt.show()
//////////////////////////////////
import pandas as pd
import numpy as np

# Load dataset
# df = pd.read_csv('your_dataset.csv')  # uncomment and replace with your file

# Step 1: Remove irrelevant columns
columns_to_remove = [
    'Curricular units 1st sem (credited)',
    'Curricular units 1st sem (enrolled)',
    'Curricular units 1st sem (evaluations)',
    'Curricular units 1st sem (approved)',
    'Curricular units 1st sem (without evaluations)',
    'Curricular units 2nd sem (credited)',
    'Curricular units 2nd sem (enrolled)',
    'Curricular units 2nd sem (evaluations)',
    'Curricular units 2nd sem (approved)',
    'Curricular units 2nd sem (grade)',
    'Curricular units 2nd sem (without evaluations)',
    'Application order',
    'Daytime/evening attendance'
]

df = df.drop(columns=columns_to_remove, errors='ignore')

# Step 2: Handle rare categories
def group_rare(df, column, threshold=50):
    counts = df[column].value_counts()
    rare = counts[counts < threshold].index
    df[column] = df[column].apply(lambda x: 'Other' if x in rare else x)
    return df

categorical_columns = [
    'Marital status', 'Application mode', 'Previous qualification',
    "Mother's qualification", "Father's qualification",
    "Mother's occupation", "Father's occupation", 'Course'
]

for col in categorical_columns:
    if col in df.columns:
        df = group_rare(df, col, threshold=50)

# Step 3: Cap numeric outliers
numeric_columns = ['Age at enrollment', 'Admission grade', 'Previous qualification (grade)']

for col in numeric_columns:
    if col in df.columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        df[col] = df[col].clip(lower=lower, upper=upper)

# Step 4: Encode target if needed
# df['Target'] = df['Target'].map({'Dropout': 0, 'Enrolled': 1, 'Graduate': 2})

# Check cleaned dataset
print(df.info())
print(df.head())
////////////////////////////////////////////////////
import pandas as pd

# Display first few rows
print("Preview of cleaned dataset:")
print(df_cleaned.head())

# Summary statistics
print("\nSummary Statistics:")
print(df_cleaned.describe())

# Distribution of target variable
print("\nDistribution of Target_num (0=Dropout, 1=Enrolled, 2=Graduate):")
print(df_cleaned['Target_num'].value_counts())

# Grouped means to understand differences by student status
print("\nAverage feature values per group:")
group_means = df_cleaned.groupby('Target_num').mean()
print(group_means)

# Correlation matrix for relationships among numeric columns
print("\nCorrelation Matrix:")
print(df_cleaned.corr())

# Identify outliers based on z-score (basic check)
from scipy import stats
z_scores = stats.zscore(df_cleaned.select_dtypes(include=['float64', 'int64']))
outliers = (abs(z_scores) > 3).sum(axis=0)
print("\nNumber of potential outliers per column:")
print(outliers)
