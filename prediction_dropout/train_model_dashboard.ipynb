{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab22b6ca-8066-48d8-a6b4-7c4ba0c98b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns available in the dataset:\n",
      "['Previous qualification (grade)', 'Admission grade', 'Age at enrollment', 'Curricular units 1st sem (approved)', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (approved)', 'Curricular units 2nd sem (grade)', 'Target']\n",
      "‚úÖ Unique values in Target: [0 1 'Enrolled']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 51\u001b[0m\n\u001b[0;32m     46\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# 6. Train-test split\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     52\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Data split completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining set:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2872\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2868\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2870\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2872\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2874\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m   2876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2877\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2878\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2879\u001b[0m     )\n\u001b[0;32m   2880\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:1909\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1879\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1880\u001b[0m \n\u001b[0;32m   1881\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1906\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1907\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1908\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1909\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1910\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2313\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   2309\u001b[0m     \u001b[38;5;66;03m# for multi-label y, map each distinct row to a string repr\u001b[39;00m\n\u001b[0;32m   2310\u001b[0m     \u001b[38;5;66;03m# using join because str(row) uses an ellipsis if len(row) > 1000\u001b[39;00m\n\u001b[0;32m   2311\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(row\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m y])\n\u001b[1;32m-> 2313\u001b[0m classes, y_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2314\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m classes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2316\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\_arraysetops_impl.py:291\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    289\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 291\u001b[0m     ret \u001b[38;5;241m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    292\u001b[0m                     equal_nan\u001b[38;5;241m=\u001b[39mequal_nan, inverse_shape\u001b[38;5;241m=\u001b[39mar\u001b[38;5;241m.\u001b[39mshape, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\_arraysetops_impl.py:355\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan, inverse_shape, axis)\u001b[0m\n\u001b[0;32m    352\u001b[0m optional_indices \u001b[38;5;241m=\u001b[39m return_index \u001b[38;5;129;01mor\u001b[39;00m return_inverse\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_indices:\n\u001b[1;32m--> 355\u001b[0m     perm \u001b[38;5;241m=\u001b[39m ar\u001b[38;5;241m.\u001b[39margsort(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmergesort\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_index \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquicksort\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    356\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# train_model_dashboard.ipynb\n",
    "\n",
    "# ===================================================\n",
    "# 1. Imports\n",
    "# ===================================================\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ===================================================\n",
    "# 2. Load dataset\n",
    "# ===================================================\n",
    "df = pd.read_csv(\"cleaned_student_data_v2.csv\")  # replace with your dataset file\n",
    "\n",
    "# Show columns\n",
    "print(\"Columns available in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ===================================================\n",
    "# 3. Select only required columns\n",
    "# ===================================================\n",
    "selected_columns = [\n",
    "    'Previous qualification (grade)',\n",
    "    'Admission grade',\n",
    "    'Age at enrollment',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Target'\n",
    "]\n",
    "df = df[selected_columns].copy()\n",
    "\n",
    "# ===================================================\n",
    "# 4. Convert target to numeric\n",
    "# ===================================================\n",
    "df['Target'] = df['Target'].replace({\"Dropout\": 0, \"Graduate\": 1})\n",
    "print(\"‚úÖ Unique values in Target:\", df['Target'].unique())\n",
    "\n",
    "# ===================================================\n",
    "# 5. Separate features and target\n",
    "# ===================================================\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# ===================================================\n",
    "# 6. Train-test split\n",
    "# ===================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"‚úÖ Data split completed!\")\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Test set:\", X_test.shape)\n",
    "\n",
    "# ===================================================\n",
    "# 7. Handle imbalance with SMOTE\n",
    "# ===================================================\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "from collections import Counter\n",
    "print(\"\\nüìà Class distribution after SMOTE:\", Counter(y_train_resampled))\n",
    "\n",
    "# ===================================================\n",
    "# 8. Train CatBoost model\n",
    "# ===================================================\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=5,\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=100,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, eval_set=(X_test, y_test))\n",
    "\n",
    "# ===================================================\n",
    "# 9. Evaluate model\n",
    "# ===================================================\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"\\nüéØ Model Accuracy: {accuracy_score(y_test, y_pred):.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ===================================================\n",
    "# 10. Save model\n",
    "# ===================================================\n",
    "model.save_model(\"best_catboost_model_dashboard.pkl\")\n",
    "print(\"\\nüíæ Model saved as 'best_catboost_model_dashboard.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bbe033-ac0d-405c-87bc-6f51ff5e7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_dashboard.ipynb\n",
    "\n",
    "# ===================================================\n",
    "# 1. Imports\n",
    "# ===================================================\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ===================================================\n",
    "# 2. Load dataset\n",
    "# ===================================================\n",
    "df = pd.read_csv(\"student_data.csv\")  # replace with your dataset file\n",
    "\n",
    "# Show columns\n",
    "print(\"Columns available in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ===================================================\n",
    "# 3. Select only required columns\n",
    "# ===================================================\n",
    "selected_columns = [\n",
    "    'Previous qualification (grade)',\n",
    "    'Admission grade',\n",
    "    'Age at enrollment',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Target'\n",
    "]\n",
    "df = df[selected_columns].copy()\n",
    "\n",
    "# ===================================================\n",
    "# 4. Convert target to numeric\n",
    "# ===================================================\n",
    "df['Target'] = df['Target'].replace({\"Dropout\": 0, \"Graduate\": 1})\n",
    "print(\"‚úÖ Unique values in Target:\", df['Target'].unique())\n",
    "\n",
    "# ===================================================\n",
    "# 5. Separate features and target\n",
    "# ===================================================\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# ===================================================\n",
    "# 6. Train-test split\n",
    "# ===================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"‚úÖ Data split completed!\")\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Test set:\", X_test.shape)\n",
    "\n",
    "# ===================================================\n",
    "# 7. Handle imbalance with SMOTE\n",
    "# ===================================================\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "from collections import Counter\n",
    "print(\"\\nüìà Class distribution after SMOTE:\", Counter(y_train_resampled))\n",
    "\n",
    "# ===================================================\n",
    "# 8. Train CatBoost model\n",
    "# ===================================================\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=5,\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=100,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, eval_set=(X_test, y_test))\n",
    "\n",
    "# ===================================================\n",
    "# 9. Evaluate model\n",
    "# ===================================================\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"\\nüéØ Model Accuracy: {accuracy_score(y_test, y_pred):.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ===================================================\n",
    "# 10. Save model\n",
    "# ===================================================\n",
    "model.save_model(\"best_catboost_model_dashboard.pkl\")\n",
    "print(\"\\nüíæ Model saved as 'best_catboost_model_dashboard.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1dec17-0e23-404c-a4b4-d20c3567b535",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'student_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 2. Load dataset\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# replace with your dataset file\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Show columns\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns available in the dataset:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'student_data.csv'"
     ]
    }
   ],
   "source": [
    "# train_model_dashboard.ipynb\n",
    "\n",
    "# ===================================================\n",
    "# 1. Imports\n",
    "# ===================================================\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ===================================================\n",
    "# 2. Load dataset\n",
    "# ===================================================\n",
    "df = pd.read_csv(\"student_data.csv\")  # replace with your dataset file\n",
    "\n",
    "# Show columns\n",
    "print(\"Columns available in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ===================================================\n",
    "# 3. Select only required columns\n",
    "# ===================================================\n",
    "selected_columns = [\n",
    "    'Previous qualification (grade)',\n",
    "    'Admission grade',\n",
    "    'Age at enrollment',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Target'\n",
    "]\n",
    "df = df[selected_columns].copy()\n",
    "\n",
    "# ===================================================\n",
    "# 4. Convert target to numeric\n",
    "# ===================================================\n",
    "df['Target'] = df['Target'].replace({\"Dropout\": 0, \"Graduate\": 1})\n",
    "print(\"‚úÖ Unique values in Target:\", df['Target'].unique())\n",
    "\n",
    "# ===================================================\n",
    "# 5. Separate features and target\n",
    "# ===================================================\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# ===================================================\n",
    "# 6. Train-test split\n",
    "# ===================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"‚úÖ Data split completed!\")\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Test set:\", X_test.shape)\n",
    "\n",
    "# ===================================================\n",
    "# 7. Handle imbalance with SMOTE\n",
    "# ===================================================\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "from collections import Counter\n",
    "print(\"\\nüìà Class distribution after SMOTE:\", Counter(y_train_resampled))\n",
    "\n",
    "# ===================================================\n",
    "# 8. Train CatBoost model\n",
    "# ===================================================\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=5,\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=100,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, eval_set=(X_test, y_test))\n",
    "\n",
    "# ===================================================\n",
    "# 9. Evaluate model\n",
    "# ===================================================\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"\\nüéØ Model Accuracy: {accuracy_score(y_test, y_pred):.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ===================================================\n",
    "# 10. Save model\n",
    "# ===================================================\n",
    "model.save_model(\"best_catboost_model_dashboard.pkl\")\n",
    "print(\"\\nüíæ Model saved as 'best_catboost_model_dashboard.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56803b81-eb51-4688-8479-fa244fdad017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns available in the dataset:\n",
      "['Previous qualification (grade)', 'Admission grade', 'Age at enrollment', 'Curricular units 1st sem (approved)', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (approved)', 'Curricular units 2nd sem (grade)', 'Target']\n",
      "‚úÖ Unique values in Target: [0 1 'Enrolled']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 51\u001b[0m\n\u001b[0;32m     46\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# 6. Train-test split\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     52\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Data split completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining set:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2872\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2868\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2870\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2872\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2874\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m   2876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2877\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2878\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2879\u001b[0m     )\n\u001b[0;32m   2880\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:1909\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1879\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1880\u001b[0m \n\u001b[0;32m   1881\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1906\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1907\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1908\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1909\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1910\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2313\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   2309\u001b[0m     \u001b[38;5;66;03m# for multi-label y, map each distinct row to a string repr\u001b[39;00m\n\u001b[0;32m   2310\u001b[0m     \u001b[38;5;66;03m# using join because str(row) uses an ellipsis if len(row) > 1000\u001b[39;00m\n\u001b[0;32m   2311\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(row\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m y])\n\u001b[1;32m-> 2313\u001b[0m classes, y_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2314\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m classes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2316\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\_arraysetops_impl.py:291\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    289\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 291\u001b[0m     ret \u001b[38;5;241m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    292\u001b[0m                     equal_nan\u001b[38;5;241m=\u001b[39mequal_nan, inverse_shape\u001b[38;5;241m=\u001b[39mar\u001b[38;5;241m.\u001b[39mshape, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\_arraysetops_impl.py:355\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan, inverse_shape, axis)\u001b[0m\n\u001b[0;32m    352\u001b[0m optional_indices \u001b[38;5;241m=\u001b[39m return_index \u001b[38;5;129;01mor\u001b[39;00m return_inverse\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_indices:\n\u001b[1;32m--> 355\u001b[0m     perm \u001b[38;5;241m=\u001b[39m ar\u001b[38;5;241m.\u001b[39margsort(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmergesort\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_index \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquicksort\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    356\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# train_model_dashboard.ipynb\n",
    "\n",
    "# ===================================================\n",
    "# 1. Imports\n",
    "# ===================================================\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ===================================================\n",
    "# 2. Load dataset\n",
    "# ===================================================\n",
    "df = pd.read_csv(\"cleaned_student_data_v2.csv\")  # replace with your dataset file\n",
    "\n",
    "# Show columns\n",
    "print(\"Columns available in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ===================================================\n",
    "# 3. Select only required columns\n",
    "# ===================================================\n",
    "selected_columns = [\n",
    "    'Previous qualification (grade)',\n",
    "    'Admission grade',\n",
    "    'Age at enrollment',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Target'\n",
    "]\n",
    "df = df[selected_columns].copy()\n",
    "\n",
    "# ===================================================\n",
    "# 4. Convert target to numeric\n",
    "# ===================================================\n",
    "df['Target'] = df['Target'].replace({\"Dropout\": 0, \"Graduate\": 1})\n",
    "print(\"‚úÖ Unique values in Target:\", df['Target'].unique())\n",
    "\n",
    "# ===================================================\n",
    "# 5. Separate features and target\n",
    "# ===================================================\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# ===================================================\n",
    "# 6. Train-test split\n",
    "# ===================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"‚úÖ Data split completed!\")\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Test set:\", X_test.shape)\n",
    "\n",
    "# ===================================================\n",
    "# 7. Handle imbalance with SMOTE\n",
    "# ===================================================\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "from collections import Counter\n",
    "print(\"\\nüìà Class distribution after SMOTE:\", Counter(y_train_resampled))\n",
    "\n",
    "# ===================================================\n",
    "# 8. Train CatBoost model\n",
    "# ===================================================\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=5,\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=100,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, eval_set=(X_test, y_test))\n",
    "\n",
    "# ===================================================\n",
    "# 9. Evaluate model\n",
    "# ===================================================\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"\\nüéØ Model Accuracy: {accuracy_score(y_test, y_pred):.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ===================================================\n",
    "# 10. Save model\n",
    "# ===================================================\n",
    "model.save_model(\"best_catboost_model_dashboard.pkl\")\n",
    "print(\"\\nüíæ Model saved as 'best_catboost_model_dashboard.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b238fb9-15ad-444c-a2ec-996c67538ed5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression expected after dictionary key and ':' (2484574044.py, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 41\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"Graduate\":\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expression expected after dictionary key and ':'\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Student Dropout Prediction Training Notebook\n",
    "# ===============================\n",
    "\n",
    "# 1Ô∏è‚É£ Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "# 2Ô∏è‚É£ Load dataset\n",
    "df = pd.read_csv(\"cleaned_student_data.csv\")  # replace with your actual file\n",
    "\n",
    "# Show available columns\n",
    "print(\"Columns available in the dataset:\")\n",
    "for idx, col in enumerate(df.columns):\n",
    "    print(f\"{idx}: {col}\")\n",
    "\n",
    "# ‚úÖ Selected columns based on previous discussion\n",
    "selected_columns = [\n",
    "    'Previous qualification (grade)',\n",
    "    'Admission grade',\n",
    "    'Age at enrollment',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Target'\n",
    "]\n",
    "\n",
    "df = df[selected_columns]\n",
    "\n",
    "# 3Ô∏è‚É£ Clean Target column\n",
    "# Convert 'Dropout' -> 0, 'Graduate' and 'Enrolled' -> 1\n",
    "df['Target'] = df['Target'].replace({\n",
    "    \"Dropout\": 0,\n",
    "    \"Graduate\":1 \n",
    "})\n",
    "\n",
    "print(\"\\n‚úÖ Unique values in Target after cleaning:\", df['Target'].unique())\n",
    "\n",
    "# 4Ô∏è‚É£ Handle missing values (if any)\n",
    "df = df.dropna()  # simple approach, can be enhanced\n",
    "\n",
    "# 5Ô∏è‚É£ Prepare features and target\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# 6Ô∏è‚É£ Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"\\n‚úÖ Data split completed!\")\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Test set:\", X_test.shape)\n",
    "\n",
    "# 7Ô∏è‚É£ Check class distribution before SMOTE\n",
    "print(\"\\nüìä Class distribution before SMOTE:\")\n",
    "print(Counter(y_train))\n",
    "\n",
    "# 8Ô∏è‚É£ Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nüìà Class distribution after SMOTE:\")\n",
    "print(Counter(y_train_resampled))\n",
    "\n",
    "# 9Ô∏è‚É£ Train CatBoost Classifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, eval_set=(X_test, y_test), verbose=100)\n",
    "\n",
    "# 10Ô∏è‚É£ Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nüéØ Model Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 11Ô∏è‚É£ Save the trained model for dashboard\n",
    "with open(\"best_catboost_model_final.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"\\nüíæ Model saved as 'best_catboost_model_final.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c926d931-140a-40fe-8060-1fadd06cb3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns available in the dataset:\n",
      "0: Target_num\n",
      "1: Curricular units 1st sem (grade)\n",
      "2: Admission grade\n",
      "3: Previous qualification (grade)\n",
      "4: Age at enrollment\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Curricular units 1st sem (approved)', 'Curricular units 2nd sem (approved)', 'Curricular units 2nd sem (grade)', 'Target'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# ‚úÖ Selected columns based on previous discussion\u001b[39;00m\n\u001b[0;32m     24\u001b[0m selected_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrevious qualification (grade)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdmission grade\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     33\u001b[0m ]\n\u001b[1;32m---> 35\u001b[0m df \u001b[38;5;241m=\u001b[39m df[selected_columns]\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 3Ô∏è‚É£ Clean Target column\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Convert 'Dropout' -> 0, 'Graduate' and 'Enrolled' -> 1\u001b[39;00m\n\u001b[0;32m     39\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace({\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDropout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraduate\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m1\u001b[39m \n\u001b[0;32m     42\u001b[0m })\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Curricular units 1st sem (approved)', 'Curricular units 2nd sem (approved)', 'Curricular units 2nd sem (grade)', 'Target'] not in index\""
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Student Dropout Prediction Training Notebook\n",
    "# ===============================\n",
    "\n",
    "# 1Ô∏è‚É£ Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "# 2Ô∏è‚É£ Load dataset\n",
    "df = pd.read_csv(\"cleaned_student_data.csv\")  # replace with your actual file\n",
    "\n",
    "# Show available columns\n",
    "print(\"Columns available in the dataset:\")\n",
    "for idx, col in enumerate(df.columns):\n",
    "    print(f\"{idx}: {col}\")\n",
    "\n",
    "# ‚úÖ Selected columns based on previous discussion\n",
    "selected_columns = [\n",
    "    'Previous qualification (grade)',\n",
    "    'Admission grade',\n",
    "    'Age at enrollment',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Target'\n",
    "]\n",
    "\n",
    "df = df[selected_columns]\n",
    "\n",
    "# 3Ô∏è‚É£ Clean Target column\n",
    "# Convert 'Dropout' -> 0, 'Graduate' and 'Enrolled' -> 1\n",
    "df['Target'] = df['Target'].replace({\n",
    "    \"Dropout\": 0,\n",
    "    \"Graduate\":1 \n",
    "})\n",
    "\n",
    "print(\"\\n‚úÖ Unique values in Target after cleaning:\", df['Target'].unique())\n",
    "\n",
    "# 4Ô∏è‚É£ Handle missing values (if any)\n",
    "df = df.dropna()  # simple approach, can be enhanced\n",
    "\n",
    "# 5Ô∏è‚É£ Prepare features and target\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# 6Ô∏è‚É£ Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"\\n‚úÖ Data split completed!\")\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Test set:\", X_test.shape)\n",
    "\n",
    "# 7Ô∏è‚É£ Check class distribution before SMOTE\n",
    "print(\"\\nüìä Class distribution before SMOTE:\")\n",
    "print(Counter(y_train))\n",
    "\n",
    "# 8Ô∏è‚É£ Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nüìà Class distribution after SMOTE:\")\n",
    "print(Counter(y_train_resampled))\n",
    "\n",
    "# 9Ô∏è‚É£ Train CatBoost Classifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, eval_set=(X_test, y_test), verbose=100)\n",
    "\n",
    "# 10Ô∏è‚É£ Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nüéØ Model Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 11Ô∏è‚É£ Save the trained model for dashboard\n",
    "with open(\"best_catboost_model_final.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"\\nüíæ Model saved as 'best_catboost_model_final.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c92f39-2e02-46be-ae43-ee6438cbf7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns available in the dataset:\n",
      "0: Target_num\n",
      "1: Curricular units 1st sem (grade)\n",
      "2: Admission grade\n",
      "3: Previous qualification (grade)\n",
      "4: Age at enrollment\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Curricular units 1st sem (approved)', 'Curricular units 2nd sem (approved)', 'Curricular units 2nd sem (grade)', 'Target'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 34\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# ‚úÖ Selected columns\u001b[39;00m\n\u001b[0;32m     23\u001b[0m selected_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrevious qualification (grade)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdmission grade\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     32\u001b[0m ]\n\u001b[1;32m---> 34\u001b[0m df \u001b[38;5;241m=\u001b[39m df[selected_columns]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 3Ô∏è‚É£ Clean Target column\u001b[39;00m\n\u001b[0;32m     37\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace({\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDropout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraduate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnrolled\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     41\u001b[0m })\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Curricular units 1st sem (approved)', 'Curricular units 2nd sem (approved)', 'Curricular units 2nd sem (grade)', 'Target'] not in index\""
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Student Dropout Prediction Training Notebook\n",
    "# ===============================\n",
    "\n",
    "# 1Ô∏è‚É£ Import libraries\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "# 2Ô∏è‚É£ Load dataset\n",
    "df = pd.read_csv(\"cleaned_student_data.csv\")  \n",
    "\n",
    "# Show available columns\n",
    "print(\"Columns available in the dataset:\")\n",
    "for idx, col in enumerate(df.columns):\n",
    "    print(f\"{idx}: {col}\")\n",
    "\n",
    "# ‚úÖ Selected columns\n",
    "selected_columns = [\n",
    "    'Previous qualification (grade)',\n",
    "    'Admission grade',\n",
    "    'Age at enrollment',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Target'\n",
    "]\n",
    "\n",
    "df = df[selected_columns]\n",
    "\n",
    "# 3Ô∏è‚É£ Clean Target column\n",
    "df['Target'] = df['Target'].replace({\n",
    "    \"Dropout\": 0,\n",
    "    \"Graduate\": 1,\n",
    "    \"Enrolled\": 1\n",
    "})\n",
    "print(\"\\n‚úÖ Unique values in Target after cleaning:\", df['Target'].unique())\n",
    "\n",
    "# 4Ô∏è‚É£ Handle missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# 5Ô∏è‚É£ Prepare features and target\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# 6Ô∏è‚É£ Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"\\n‚úÖ Data split completed!\")\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Test set:\", X_test.shape)\n",
    "\n",
    "# 7Ô∏è‚É£ Check class distribution before SMOTE\n",
    "print(\"\\nüìä Class distribution before SMOTE:\")\n",
    "print(Counter(y_train))\n",
    "\n",
    "# 8Ô∏è‚É£ Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(\"\\nüìà Class distribution after SMOTE:\")\n",
    "print(Counter(y_train_resampled))\n",
    "\n",
    "# 9Ô∏è‚É£ Train CatBoost Classifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=100,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_resampled, y_train_resampled, eval_set=(X_test, y_test), verbose=100)\n",
    "\n",
    "# 10Ô∏è‚É£ Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nüéØ Model Accuracy: {accuracy:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 11Ô∏è‚É£ Save the model\n",
    "with open(\"best_catboost_model_final.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"\\nüíæ Model saved as 'best_catboost_model_final.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b68a58-c06c-4e22-9430-bada5abbcccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns available in the dataset:\n",
      "0: Previous qualification (grade)\n",
      "1: Admission grade\n",
      "2: Age at enrollment\n",
      "3: Curricular units 1st sem (approved)\n",
      "4: Curricular units 1st sem (grade)\n",
      "5: Curricular units 2nd sem (approved)\n",
      "6: Curricular units 2nd sem (grade)\n",
      "7: Target\n",
      "\n",
      "‚úÖ Unique values in Target after cleaning: [0 1]\n",
      "\n",
      "‚úÖ Data split completed!\n",
      "Training set: (3539, 7)\n",
      "Test set: (885, 7)\n",
      "\n",
      "üìä Class distribution before SMOTE:\n",
      "Counter({1: 2402, 0: 1137})\n",
      "\n",
      "üìà Class distribution after SMOTE:\n",
      "Counter({0: 2402, 1: 2402})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\AppData\\Local\\Temp\\ipykernel_8748\\1426826069.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Target'] = df['Target'].replace({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8172356\ttest: 0.8327684\tbest: 0.8327684 (0)\ttotal: 137ms\tremaining: 2m 17s\n",
      "100:\tlearn: 0.8819734\ttest: 0.8429379\tbest: 0.8474576 (78)\ttotal: 743ms\tremaining: 6.62s\n",
      "200:\tlearn: 0.9154871\ttest: 0.8361582\tbest: 0.8474576 (78)\ttotal: 1.59s\tremaining: 6.33s\n",
      "300:\tlearn: 0.9331807\ttest: 0.8338983\tbest: 0.8474576 (78)\ttotal: 2.17s\tremaining: 5.05s\n",
      "400:\tlearn: 0.9479600\ttest: 0.8338983\tbest: 0.8474576 (78)\ttotal: 2.71s\tremaining: 4.05s\n",
      "500:\tlearn: 0.9612823\ttest: 0.8305085\tbest: 0.8474576 (78)\ttotal: 3.27s\tremaining: 3.26s\n",
      "600:\tlearn: 0.9708576\ttest: 0.8338983\tbest: 0.8474576 (78)\ttotal: 3.81s\tremaining: 2.53s\n",
      "700:\tlearn: 0.9766861\ttest: 0.8338983\tbest: 0.8474576 (78)\ttotal: 4.34s\tremaining: 1.85s\n",
      "800:\tlearn: 0.9814738\ttest: 0.8282486\tbest: 0.8474576 (78)\ttotal: 4.88s\tremaining: 1.21s\n",
      "900:\tlearn: 0.9852206\ttest: 0.8271186\tbest: 0.8474576 (78)\ttotal: 5.44s\tremaining: 598ms\n",
      "999:\tlearn: 0.9879267\ttest: 0.8248588\tbest: 0.8474576 (78)\ttotal: 5.96s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8474576271\n",
      "bestIteration = 78\n",
      "\n",
      "Shrink model to first 79 iterations.\n",
      "\n",
      "üéØ Model Accuracy: 0.8475\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76       284\n",
      "           1       0.89      0.89      0.89       601\n",
      "\n",
      "    accuracy                           0.85       885\n",
      "   macro avg       0.82      0.83      0.83       885\n",
      "weighted avg       0.85      0.85      0.85       885\n",
      "\n",
      "Confusion Matrix:\n",
      "[[218  66]\n",
      " [ 69 532]]\n",
      "\n",
      "üíæ Model saved as 'best_catboost_model_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Student Dropout Prediction Training Notebook\n",
    "# ===============================\n",
    "\n",
    "# 1Ô∏è‚É£ Import libraries\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "# 2Ô∏è‚É£ Load dataset\n",
    "df = pd.read_csv(\"cleaned_student_data_v2.csv\")  \n",
    "\n",
    "# Show available columns\n",
    "print(\"Columns available in the dataset:\")\n",
    "for idx, col in enumerate(df.columns):\n",
    "    print(f\"{idx}: {col}\")\n",
    "\n",
    "# ‚úÖ Selected columns\n",
    "selected_columns = [\n",
    "    'Previous qualification (grade)',\n",
    "    'Admission grade',\n",
    "    'Age at enrollment',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Target'\n",
    "]\n",
    "\n",
    "df = df[selected_columns]\n",
    "\n",
    "# 3Ô∏è‚É£ Clean Target column\n",
    "df['Target'] = df['Target'].replace({\n",
    "    \"Dropout\": 0,\n",
    "    \"Graduate\": 1,\n",
    "    \"Enrolled\": 1\n",
    "})\n",
    "print(\"\\n‚úÖ Unique values in Target after cleaning:\", df['Target'].unique())\n",
    "\n",
    "# 4Ô∏è‚É£ Handle missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# 5Ô∏è‚É£ Prepare features and target\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# 6Ô∏è‚É£ Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"\\n‚úÖ Data split completed!\")\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Test set:\", X_test.shape)\n",
    "\n",
    "# 7Ô∏è‚É£ Check class distribution before SMOTE\n",
    "print(\"\\nüìä Class distribution before SMOTE:\")\n",
    "print(Counter(y_train))\n",
    "\n",
    "# 8Ô∏è‚É£ Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(\"\\nüìà Class distribution after SMOTE:\")\n",
    "print(Counter(y_train_resampled))\n",
    "\n",
    "# 9Ô∏è‚É£ Train CatBoost Classifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=100,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_resampled, y_train_resampled, eval_set=(X_test, y_test), verbose=100)\n",
    "\n",
    "# 10Ô∏è‚É£ Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nüéØ Model Accuracy: {accuracy:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 11Ô∏è‚É£ Save the model\n",
    "with open(\"best_catboost_model_final.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"\\nüíæ Model saved as 'best_catboost_model_final.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "195d293c-9d0e-4c50-ad25-19efc3647a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns available in the dataset:\n",
      "['Previous qualification (grade)', 'Admission grade', 'Age at enrollment', 'Curricular units 1st sem (approved)', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (approved)', 'Curricular units 2nd sem (grade)', 'Target']\n",
      "\n",
      "First 20 rows of the dataset:\n",
      "    Previous qualification (grade)  Admission grade  Age at enrollment  \\\n",
      "0                            122.0            127.3                 20   \n",
      "1                            160.0            142.5                 19   \n",
      "2                            122.0            124.8                 19   \n",
      "3                            122.0            119.6                 20   \n",
      "4                            100.0            141.5                 45   \n",
      "5                            133.1            114.8                 50   \n",
      "6                            142.0            128.4                 18   \n",
      "7                            119.0            113.1                 22   \n",
      "8                            137.0            129.3                 21   \n",
      "9                            138.0            123.0                 18   \n",
      "10                           139.0            130.6                 18   \n",
      "11                           136.0            119.3                 18   \n",
      "12                           133.0            130.2                 19   \n",
      "13                           110.0            111.8                 21   \n",
      "14                           149.0            137.1                 18   \n",
      "15                           127.0            120.7                 20   \n",
      "16                           137.0            137.4                 18   \n",
      "17                           135.0            127.3                 18   \n",
      "18                           137.0            136.3                 20   \n",
      "19                           140.0            124.6                 18   \n",
      "\n",
      "    Curricular units 1st sem (approved)  Curricular units 1st sem (grade)  \\\n",
      "0                                     0                          0.000000   \n",
      "1                                     6                         14.000000   \n",
      "2                                     0                          0.000000   \n",
      "3                                     6                         13.428571   \n",
      "4                                     5                         12.333333   \n",
      "5                                     5                         11.857143   \n",
      "6                                     7                         13.300000   \n",
      "7                                     0                          0.000000   \n",
      "8                                     6                         13.875000   \n",
      "9                                     5                         11.400000   \n",
      "10                                    6                         12.333333   \n",
      "11                                    7                         13.214286   \n",
      "12                                    0                          0.000000   \n",
      "13                                    6                         10.571429   \n",
      "14                                    4                         13.250000   \n",
      "15                                    5                         13.200000   \n",
      "16                                    1                         12.000000   \n",
      "17                                    7                         13.306250   \n",
      "18                                    4                         12.500000   \n",
      "19                                    6                         11.666667   \n",
      "\n",
      "    Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
      "0                                     0                          0.000000   \n",
      "1                                     6                         13.666667   \n",
      "2                                     0                          0.000000   \n",
      "3                                     5                         12.400000   \n",
      "4                                     6                         13.000000   \n",
      "5                                     5                         11.500000   \n",
      "6                                     8                         14.345000   \n",
      "7                                     0                          0.000000   \n",
      "8                                     6                         14.142857   \n",
      "9                                     2                         13.500000   \n",
      "10                                    5                         14.200000   \n",
      "11                                    7                         13.214286   \n",
      "12                                    0                          0.000000   \n",
      "13                                    5                         11.000000   \n",
      "14                                    5                         12.000000   \n",
      "15                                    0                          0.000000   \n",
      "16                                    2                         11.000000   \n",
      "17                                    8                         14.545000   \n",
      "18                                    4                         12.250000   \n",
      "19                                    6                         13.500000   \n",
      "\n",
      "      Target  \n",
      "0    Dropout  \n",
      "1   Graduate  \n",
      "2    Dropout  \n",
      "3   Graduate  \n",
      "4   Graduate  \n",
      "5   Graduate  \n",
      "6   Graduate  \n",
      "7    Dropout  \n",
      "8   Graduate  \n",
      "9    Dropout  \n",
      "10  Graduate  \n",
      "11  Graduate  \n",
      "12   Dropout  \n",
      "13  Graduate  \n",
      "14  Graduate  \n",
      "15   Dropout  \n",
      "16  Enrolled  \n",
      "17  Graduate  \n",
      "18  Graduate  \n",
      "19  Enrolled  \n",
      "\n",
      "Feature ranges:\n",
      "       Previous qualification (grade)  Admission grade  Age at enrollment  \\\n",
      "count                     4424.000000      4424.000000        4424.000000   \n",
      "mean                       132.613314       126.978119          23.265145   \n",
      "std                         13.188332        14.482001           7.587816   \n",
      "min                         95.000000        95.000000          17.000000   \n",
      "25%                        125.000000       117.900000          19.000000   \n",
      "50%                        133.100000       126.100000          20.000000   \n",
      "75%                        140.000000       134.800000          25.000000   \n",
      "max                        190.000000       190.000000          70.000000   \n",
      "\n",
      "       Curricular units 1st sem (approved)  Curricular units 1st sem (grade)  \\\n",
      "count                          4424.000000                       4424.000000   \n",
      "mean                              4.706600                         10.640822   \n",
      "std                               3.094238                          4.843663   \n",
      "min                               0.000000                          0.000000   \n",
      "25%                               3.000000                         11.000000   \n",
      "50%                               5.000000                         12.285714   \n",
      "75%                               6.000000                         13.400000   \n",
      "max                              26.000000                         18.875000   \n",
      "\n",
      "       Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \n",
      "count                          4424.000000                       4424.000000  \n",
      "mean                              4.435805                         10.230206  \n",
      "std                               3.014764                          5.210808  \n",
      "min                               0.000000                          0.000000  \n",
      "25%                               2.000000                         10.750000  \n",
      "50%                               5.000000                         12.200000  \n",
      "75%                               6.000000                         13.333333  \n",
      "max                              20.000000                         18.571429  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"cleaned_student_data_v2.csv\")\n",
    "\n",
    "# Show column names\n",
    "print(\"Columns available in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Show first 20 rows\n",
    "print(\"\\nFirst 20 rows of the dataset:\")\n",
    "print(df.head(20))\n",
    "\n",
    "# Show min/max values for numeric features\n",
    "numeric_cols = df.columns.drop(\"Target\")\n",
    "print(\"\\nFeature ranges:\")\n",
    "print(df[numeric_cols].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbea8cf-24aa-4fe5-9800-f6d9ec44f278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
